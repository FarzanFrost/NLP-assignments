{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b979ea02-2591-41f2-80c4-ba634a79fc97",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Categories: 15\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "print(\"Total Categories:\",len(brown.categories()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c08f7b42-478f-4b3e-94db-a274da35b8c6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "print(brown.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "168d6a02-61eb-41b1-9492-17d064f82cf7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['There', 'were', 'thirty-eight', 'patients', 'on', 'the', 'bus', 'the', 'morning', 'I', 'left', 'for', 'Hanover', ',', 'most', 'of', 'them', 'disturbed', 'and', 'hallucinating', '.'], ['An', 'interne', ',', 'a', 'nurse', 'and', 'two', 'attendants', 'were', 'in', 'charge', 'of', 'us', '.'], ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenized sentences\n",
    "brown.sents(categories='mystery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3840218b-06c6-40a3-bfb1-6cedd9b37a7f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('There', 'EX'), ('were', 'BED'), ('thirty-eight', 'CD'), ('patients', 'NNS'), ('on', 'IN'), ('the', 'AT'), ('bus', 'NN'), ('the', 'AT'), ('morning', 'NN'), ('I', 'PPSS'), ('left', 'VBD'), ('for', 'IN'), ('Hanover', 'NP'), (',', ','), ('most', 'AP'), ('of', 'IN'), ('them', 'PPO'), ('disturbed', 'VBN'), ('and', 'CC'), ('hallucinating', 'VBG'), ('.', '.')], [('An', 'AT'), ('interne', 'NN'), (',', ','), ('a', 'AT'), ('nurse', 'NN'), ('and', 'CC'), ('two', 'CD'), ('attendants', 'NNS'), ('were', 'BED'), ('in', 'IN'), ('charge', 'NN'), ('of', 'IN'), ('us', 'PPO'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS(parts of speech) tagged sentences\n",
    "brown.tagged_sents(categories='mystery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c63308-1259-4aa6-bf96-2efea5ba14da",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get sentences in natural form\n",
    "sentences = brown.sents(categories='mystery')\n",
    "sentences = [' '.join(sentence_token) for sentence_token in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9477e322-4402-4b22-84c3-e0dd6fdb186a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There were thirty-eight patients on the bus the morning I left for Hanover , most of them disturbed and hallucinating .', 'An interne , a nurse and two attendants were in charge of us .', \"I felt lonely and depressed as I stared out the bus window at Chicago's grim , dirty West Side .\", 'It seemed incredible , as I listened to the monotonous drone of voices and smelled the fetid odors coming from the patients , that technically I was a ward of the state of Illinois , going to a hospital for the mentally ill .', 'I suddenly thought of Mary Jane Brennan , the way her pretty eyes could flash with anger , her quiet competence , the gentleness and sweetness that lay just beneath the surface of her defenses .']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11962018-a6db-4318-8a97-d2f0a64f330d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('patients', 'NNS'), ('bus', 'NN'), ('morning', 'NN'), ('Hanover', 'NP'), ('interne', 'NN'), ('nurse', 'NN'), ('attendants', 'NNS'), ('charge', 'NN'), ('bus', 'NN'), ('window', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# Get tagged words\n",
    "tagged_words = brown.tagged_words(categories='mystery')\n",
    "# Get nouns from tagged words\n",
    "nouns = [(word,tag) for word, tag in tagged_words if any(noun_tag in tag for noun_tag in ['NP', 'NN'])]\n",
    "print(nouns[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0219fd28-f349-48c2-85b7-dabd7713556c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'cotton', 'cotton-oil', 'cpi', 'cpu', 'crude', 'dfl', 'dlr', 'dmk', 'earn', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-oil', 'heat', 'hog', 'housing', 'income', 'instal-debt', 'interest', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-oil', 'livestock', 'lumber', 'meal-feed', 'money-fx', 'money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', 'oilseed', 'orange', 'palladium', 'palm-oil', 'palmkernel', 'pet-chem', 'platinum', 'potato', 'propane', 'rand', 'rape-oil', 'rapeseed', 'reserves', 'retail', 'rice', 'rubber', 'rye', 'ship', 'silver', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'strategic-metal', 'sugar', 'sun-meal', 'sun-oil', 'sunseed', 'tea', 'tin', 'trade', 'veg-oil', 'wheat', 'wpi', 'yen', 'zinc']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import reuters\n",
    "print(reuters.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce3863b5-c198-4f95-9150-0271398943f4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test/16118', 'test/18534', 'test/18540', 'test/18664', 'test/18665', 'test/18672', 'test/18911', 'test/19875', 'test/20106', 'test/20116', 'training/1035', 'training/1036', 'training/10602', 'training/10604', 'training/11170', 'training/11665', 'training/2618', 'training/29', 'training/3105', 'training/3708', 'training/3720', 'training/3723', 'training/3898', 'training/5883', 'training/5886', 'training/6000', 'training/6067', 'training/6197', 'training/7005', 'training/7006', 'training/7015', 'training/7036', 'training/7098', 'training/7099', 'training/9615']\n"
     ]
    }
   ],
   "source": [
    "# Fileid based access\n",
    "print(reuters.fileids(categories=['housing','income']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a882f5a8-3415-4003-bcaa-5809d1a413a9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('hike.n.01'), Synset('rise.n.09'), Synset('raise.n.01'), Synset('hike.v.01'), Synset('hike.v.02')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "word = 'hike' # Taking hike as our word of interest\n",
    "# Get word synsets\n",
    "word_synsets = wn.synsets(word)\n",
    "print(word_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1a432ae-3e7d-4106-8294-bd65a223fcd5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset Name: hike.n.01\n",
      "POS tag: n\n",
      "Definition: a long walk usually for exercise or pleasure\n",
      "Example: ['she enjoys a hike in her spare time']\n",
      "\n",
      "Synset Name: rise.n.09\n",
      "POS tag: n\n",
      "Definition: an increase in cost\n",
      "Example: ['they asked for a 10% rise in rates']\n",
      "\n",
      "Synset Name: raise.n.01\n",
      "POS tag: n\n",
      "Definition: the amount a salary is increased\n",
      "Example: ['he got a 3% raise', 'he got a wage hike']\n",
      "\n",
      "Synset Name: hike.v.01\n",
      "POS tag: v\n",
      "Definition: increase\n",
      "Example: ['The landlord hiked up the rents']\n",
      "\n",
      "Synset Name: hike.v.02\n",
      "POS tag: v\n",
      "Definition: walk a long way, as for pleasure or physical exercise\n",
      "Example: ['We were hiking in Colorado', 'hike the Rockies']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get details for each synonym in synset\n",
    "for synset in word_synsets:\n",
    "    print('Synset Name:', synset.name())\n",
    "    print('POS tag:', synset.pos())\n",
    "    print('Definition:', synset.definition())\n",
    "    print('Example:',synset.examples())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03186fd2-e873-4fd3-b98c-5cbcfe343673",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d901f3a5-c5ea-461f-883c-46c7553cc2e2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 11454),\n",
       " ('.', 6928),\n",
       " ('to', 5183),\n",
       " ('the', 4844),\n",
       " ('and', 4672),\n",
       " ('of', 4279),\n",
       " ('I', 3178),\n",
       " ('a', 3004),\n",
       " ('was', 2385),\n",
       " ('her', 2381),\n",
       " (';', 2199),\n",
       " ('it', 2128),\n",
       " ('in', 2118),\n",
       " ('not', 2101),\n",
       " ('\"', 2004),\n",
       " ('be', 1970),\n",
       " ('she', 1778),\n",
       " ('that', 1730),\n",
       " ('you', 1677),\n",
       " ('had', 1606),\n",
       " ('as', 1387),\n",
       " ('--', 1382),\n",
       " ('he', 1365),\n",
       " ('for', 1321),\n",
       " ('have', 1301),\n",
       " ('is', 1220),\n",
       " ('with', 1187),\n",
       " ('Mr', 1153),\n",
       " ('very', 1151),\n",
       " ('but', 1148),\n",
       " ('.\"', 1138),\n",
       " ('his', 1088),\n",
       " (\"'\", 1007),\n",
       " ('at', 997),\n",
       " ('s', 933),\n",
       " ('so', 924),\n",
       " ('Emma', 865),\n",
       " ('all', 835),\n",
       " ('could', 825),\n",
       " ('would', 815),\n",
       " ('been', 759),\n",
       " ('him', 758),\n",
       " ('Mrs', 699),\n",
       " ('.--', 685),\n",
       " ('on', 677),\n",
       " ('any', 651),\n",
       " ('my', 619),\n",
       " ('no', 616),\n",
       " ('Miss', 592),\n",
       " ('were', 591)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here keys are words, and values give their frequency.\n",
    "emmawords = gutenberg.words('austen-emma.txt')\n",
    "fdist = FreqDist(emmawords)\n",
    "fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e89a036-f8ee-4b55-a1a5-2c9078b14c96",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist['emma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d1884b8-5b52-446a-8f24-937e8a0cdf14",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4844"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9ce1e32a-7f35-403b-8771-fa5cf0553338",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def makeAlphaFreqDist(words):\n",
    "    adist = FreqDist()\n",
    "    pattern = re.compile(\".*[^a-z].*\")\n",
    "    for word in words:\n",
    "        if not pattern.match(word):\n",
    "            adist.update([word])\n",
    "    return adist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cc0db949-5817-44b6-93cf-47216029484c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 5183),\n",
       " ('the', 4844),\n",
       " ('and', 4672),\n",
       " ('of', 4279),\n",
       " ('a', 3004),\n",
       " ('was', 2385),\n",
       " ('her', 2381),\n",
       " ('it', 2128),\n",
       " ('in', 2118),\n",
       " ('not', 2101),\n",
       " ('be', 1970),\n",
       " ('she', 1778),\n",
       " ('that', 1730),\n",
       " ('you', 1677),\n",
       " ('had', 1606),\n",
       " ('as', 1387),\n",
       " ('he', 1365),\n",
       " ('for', 1321),\n",
       " ('have', 1301),\n",
       " ('is', 1220),\n",
       " ('with', 1187),\n",
       " ('very', 1151),\n",
       " ('but', 1148),\n",
       " ('his', 1088),\n",
       " ('at', 997),\n",
       " ('s', 933),\n",
       " ('so', 924),\n",
       " ('all', 835),\n",
       " ('could', 825),\n",
       " ('would', 815),\n",
       " ('been', 759),\n",
       " ('him', 758),\n",
       " ('on', 677),\n",
       " ('any', 651),\n",
       " ('my', 619),\n",
       " ('no', 616),\n",
       " ('were', 591),\n",
       " ('do', 580),\n",
       " ('must', 564),\n",
       " ('me', 564),\n",
       " ('will', 559),\n",
       " ('by', 558),\n",
       " ('which', 552),\n",
       " ('from', 535),\n",
       " ('or', 490),\n",
       " ('said', 484),\n",
       " ('much', 478),\n",
       " ('more', 464),\n",
       " ('an', 452),\n",
       " ('are', 447)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adist = makeAlphaFreqDist(emmawords)\n",
    "adist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84977113-f582-4a76-8090-86e7ba72b4bd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mbdist = FreqDist(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6248681a-f231-4696-8708-88b3403abfb0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bryant-stories.txt'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5\n",
    "file1 = gutenberg.fileids()[n]\n",
    "file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4969fee4-3ffe-4e6b-bc45-01b979ebbec9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Stories',\n",
       " 'to',\n",
       " 'Tell',\n",
       " 'to',\n",
       " 'Children',\n",
       " 'by',\n",
       " 'Sara',\n",
       " 'Cone',\n",
       " 'Bryant',\n",
       " '1918',\n",
       " ']',\n",
       " 'TWO',\n",
       " 'LITTLE',\n",
       " 'RIDDLES',\n",
       " 'IN',\n",
       " 'RHYME',\n",
       " 'There',\n",
       " \"'\",\n",
       " 's',\n",
       " 'a',\n",
       " 'garden',\n",
       " 'that',\n",
       " 'I',\n",
       " 'ken',\n",
       " ',',\n",
       " 'Full',\n",
       " 'of',\n",
       " 'little',\n",
       " 'gentlemen',\n",
       " ';',\n",
       " 'Little',\n",
       " 'caps',\n",
       " 'of',\n",
       " 'blue',\n",
       " 'they',\n",
       " 'wear',\n",
       " ',',\n",
       " 'And',\n",
       " 'green',\n",
       " 'ribbons',\n",
       " ',',\n",
       " 'very',\n",
       " 'fair',\n",
       " '.',\n",
       " '(',\n",
       " 'Flax',\n",
       " '.)',\n",
       " 'From',\n",
       " 'house']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "text = gutenberg.raw(file1)\n",
    "tokens = nltk.wordpunct_tokenize(text)\n",
    "tokens[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b42a936f-3173-477f-a5c0-a9a4efe92a21",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'stories',\n",
       " 'to',\n",
       " 'tell',\n",
       " 'to',\n",
       " 'children',\n",
       " 'by',\n",
       " 'sara',\n",
       " 'cone',\n",
       " 'bryant',\n",
       " '1918',\n",
       " ']',\n",
       " 'two',\n",
       " 'little',\n",
       " 'riddles',\n",
       " 'in',\n",
       " 'rhyme',\n",
       " 'there',\n",
       " \"'\",\n",
       " 's',\n",
       " 'a',\n",
       " 'garden',\n",
       " 'that',\n",
       " 'i',\n",
       " 'ken',\n",
       " ',',\n",
       " 'full',\n",
       " 'of',\n",
       " 'little',\n",
       " 'gentlemen',\n",
       " ';',\n",
       " 'little',\n",
       " 'caps',\n",
       " 'of',\n",
       " 'blue',\n",
       " 'they',\n",
       " 'wear',\n",
       " ',',\n",
       " 'and',\n",
       " 'green',\n",
       " 'ribbons',\n",
       " ',',\n",
       " 'very',\n",
       " 'fair',\n",
       " '.',\n",
       " '(',\n",
       " 'flax',\n",
       " '.)',\n",
       " 'from',\n",
       " 'house']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [w.lower() for w in tokens]\n",
    "words[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fe7748f-b3fd-44d9-82c8-fd9fe2431d56",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['two', 'little', 'riddles', 'in', 'rhyme', 'there', \"'\", 's', 'a', 'garden']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Including stop words.\n",
    "x = 12\n",
    "words[x:200+x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "32e57de7-2f9c-4a79-841d-56d1c553f8dc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 1), match='9'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile('^[a-z0-9]')\n",
    "print(pattern.match('9'))\n",
    "print(pattern.match('('))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020e7f86-607e-4929-b83a-776d3078e733",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
