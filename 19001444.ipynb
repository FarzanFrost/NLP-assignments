{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5870f32-69fe-4eb9-b06a-f7b97e3ae810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_data = \"\"\"Men like Schiaparelli watched the red planet-it is odd, by-the-bye, that for \n",
    "countless centuries Mars has been the star of war-but failed to interpret the fluctuating\n",
    "appearances of the amrkings they mapped so well. All that time, the Martians must have beeen\n",
    "getting ready. Druing the opposition of 1894, a great light was seen on the iiluminated part of the \n",
    "disk, first at the Lick Obser|vatory, then by Perrotin of Nice, and then by other observers. English\n",
    "readers heard of it first in the issue of Nautre dated August 2.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83eba64b-1603-4182-b983-f18c3113ba85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce569f0-b556-472e-a387-7a1039d531fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Men like Schiaparelli watched the red planet-it is odd, by-the-bye, that for \\ncountless centuries Mars has been the star of war-but failed to interpret the fluctuating\\nappearances of the amrkings they mapped so well.',\n",
       " 'All that time, the Martians must have beeen\\ngetting ready.',\n",
       " 'Druing the opposition of 1894, a great light was seen on the iiluminated part of the \\ndisk, first at the Lick Obser|vatory, then by Perrotin of Nice, and then by other observers.',\n",
       " 'English\\nreaders heard of it first in the issue of Nautre dated August 2.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. a.\n",
    "from nltk.tokenize import punkt\n",
    "tokenizer = punkt.PunktSentenceTokenizer()\n",
    "tokenizer.train(text_data)\n",
    "sentences = tokenizer.tokenize(text_data)\n",
    "sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e939004c-265e-48ba-9d2b-1c57949bb2d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1894', 'August 2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. b.\n",
    "regpatter = r''' (?x)\n",
    "[A-Z][a-z]*[ ]\\d\n",
    "| \\d+\n",
    "'''\n",
    "nltk.regexp_tokenize(text_data,regpatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af8f079d-a2bd-4812-8801-ad5672f3848d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['men',\n",
       " 'like',\n",
       " 'schiaparelli',\n",
       " 'watched',\n",
       " 'the',\n",
       " 'red',\n",
       " 'planetit',\n",
       " 'is',\n",
       " 'odd',\n",
       " 'bythebye',\n",
       " 'that',\n",
       " 'for',\n",
       " 'countless',\n",
       " 'centuries',\n",
       " 'mars',\n",
       " 'has',\n",
       " 'been',\n",
       " 'the',\n",
       " 'star',\n",
       " 'of',\n",
       " 'warbut',\n",
       " 'failed',\n",
       " 'to',\n",
       " 'interpret',\n",
       " 'the',\n",
       " 'fluctuating',\n",
       " 'appearances',\n",
       " 'of',\n",
       " 'the',\n",
       " 'amrkings',\n",
       " 'they',\n",
       " 'mapped',\n",
       " 'so',\n",
       " 'well',\n",
       " 'all',\n",
       " 'that',\n",
       " 'time',\n",
       " 'the',\n",
       " 'martians',\n",
       " 'must',\n",
       " 'have',\n",
       " 'beeen',\n",
       " 'getting',\n",
       " 'ready',\n",
       " 'druing',\n",
       " 'the',\n",
       " 'opposition',\n",
       " 'of',\n",
       " '1894',\n",
       " 'a',\n",
       " 'great',\n",
       " 'light',\n",
       " 'was',\n",
       " 'seen',\n",
       " 'on',\n",
       " 'the',\n",
       " 'iiluminated',\n",
       " 'part',\n",
       " 'of',\n",
       " 'the',\n",
       " 'disk',\n",
       " 'first',\n",
       " 'at',\n",
       " 'the',\n",
       " 'lick',\n",
       " 'observatory',\n",
       " 'then',\n",
       " 'by',\n",
       " 'perrotin',\n",
       " 'of',\n",
       " 'nice',\n",
       " 'and',\n",
       " 'then',\n",
       " 'by',\n",
       " 'other',\n",
       " 'observers',\n",
       " 'english',\n",
       " 'readers',\n",
       " 'heard',\n",
       " 'of',\n",
       " 'it',\n",
       " 'first',\n",
       " 'in',\n",
       " 'the',\n",
       " 'issue',\n",
       " 'of',\n",
       " 'nautre',\n",
       " 'dated',\n",
       " 'august',\n",
       " '2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. a\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "def remove_non_alphanumeric(string):\n",
    "    # Use regular expression to remove non-alphanumeric characters\n",
    "    cleaned_string = re.sub(r'[^a-zA-Z0-9\\s]', '', string)\n",
    "    return cleaned_string\n",
    "\n",
    "def tosimple(text_list):\n",
    "    return [w.lower() for w in text_list]\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "cleaned_text =tosimple( tokenize( remove_non_alphanumeric( text_data ) ) )\n",
    "\n",
    "cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc40e2bd-5250-482f-8161-6b17160c55d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words : 90\n",
      "Number of unique words : 71\n"
     ]
    }
   ],
   "source": [
    "# 2. b.\n",
    "def count_tokens(tokens):\n",
    "    # Get the total number of tokens\n",
    "    total_count = len(tokens)\n",
    "    \n",
    "    # Get the count of unique tokens\n",
    "    unique_count = len(set(tokens))\n",
    "    \n",
    "    return total_count, unique_count\n",
    "\n",
    "count_of_words,count_of_unique_words  = count_tokens(cleaned_text)\n",
    "print(f'Number of words : {count_of_words}')\n",
    "print(f'Number of unique words : {count_of_unique_words}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d937f0d-f3ca-42e2-a909-0fc48507cea1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words : 50\n",
      "Number of unique words : 49\n"
     ]
    }
   ],
   "source": [
    "#2. c.\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def remove_stop_words(tokens):\n",
    "    # Get the English stop words from NLTK\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Remove stop words from the tokens\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    \n",
    "    return filtered_tokens\n",
    "\n",
    "cleaned_text = remove_stop_words( cleaned_text )\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(w) for w in cleaned_text]\n",
    "\n",
    "count_of_words,count_of_unique_words  = count_tokens(cleaned_text)\n",
    "print(f'Number of words : {count_of_words}')\n",
    "print(f'Number of unique words : {count_of_unique_words}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a7ae653-c042-480c-ad7a-ca9ded0f5af1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1894 great\n",
      "amrkings mapped\n",
      "appearances amrkings\n",
      "august 2\n",
      "beeen getting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "#3. a.\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import FreqDist\n",
    "def alphaStopFreqDist(words):\n",
    "    # Make a new frequency distribution called asdist.\n",
    "    asdist = FreqDist()\n",
    "    \n",
    "    for word in words:\n",
    "        asdist[word] += 1\n",
    "    return asdist\n",
    "\n",
    "def bigramDist(words):\n",
    "    biDist = FreqDist()\n",
    "    uniDist = alphaStopFreqDist(words)\n",
    "    for i in range (1, len(words)):\n",
    "        if words[i-1] in uniDist and words[i] in uniDist:\n",
    "            biword = words[i-1] + ' ' + words[i]\n",
    "            biDist[biword] += 1\n",
    "    return biDist\n",
    "\n",
    "bigram = bigramDist(cleaned_text)\n",
    "for i,bigram_sent in enumerate(sorted(bigram)):\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(bigram_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b136774b-620c-409a-a02f-8f7ab5969722",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('men', 'NOUN'),\n",
       " ('like', 'ADP'),\n",
       " ('schiaparelli', 'NOUN'),\n",
       " ('watched', 'VERB'),\n",
       " ('red', 'ADJ'),\n",
       " ('planetit', 'NOUN'),\n",
       " ('odd', 'ADJ'),\n",
       " ('bythebye', 'NOUN'),\n",
       " ('countless', 'NOUN'),\n",
       " ('centuries', 'NOUN'),\n",
       " ('mars', 'VERB'),\n",
       " ('star', 'ADJ'),\n",
       " ('warbut', 'NOUN'),\n",
       " ('failed', 'VERB'),\n",
       " ('interpret', 'ADJ'),\n",
       " ('fluctuating', 'NOUN'),\n",
       " ('appearances', 'NOUN'),\n",
       " ('amrkings', 'NOUN'),\n",
       " ('mapped', 'VERB'),\n",
       " ('well', 'ADV'),\n",
       " ('time', 'NOUN'),\n",
       " ('martians', 'NOUN'),\n",
       " ('must', 'VERB'),\n",
       " ('beeen', 'VERB'),\n",
       " ('getting', 'VERB'),\n",
       " ('ready', 'ADJ'),\n",
       " ('druing', 'VERB'),\n",
       " ('opposition', 'NOUN'),\n",
       " ('1894', 'NUM'),\n",
       " ('great', 'ADJ'),\n",
       " ('light', 'ADJ'),\n",
       " ('seen', 'VERB'),\n",
       " ('iiluminated', 'ADJ'),\n",
       " ('part', 'NOUN'),\n",
       " ('disk', 'NOUN'),\n",
       " ('first', 'ADV'),\n",
       " ('lick', 'ADJ'),\n",
       " ('observatory', 'NOUN'),\n",
       " ('perrotin', 'NOUN'),\n",
       " ('nice', 'ADJ'),\n",
       " ('observers', 'NOUN'),\n",
       " ('english', 'ADJ'),\n",
       " ('readers', 'NOUN'),\n",
       " ('heard', 'VERB'),\n",
       " ('first', 'ADJ'),\n",
       " ('issue', 'NOUN'),\n",
       " ('nautre', 'ADV'),\n",
       " ('dated', 'VERB'),\n",
       " ('august', 'ADJ'),\n",
       " ('2', 'NUM')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. b.\n",
    "from nltk import pos_tag\n",
    "tagged_sent = pos_tag(cleaned_text, tagset='universal')\n",
    "tagged_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "954dfc7e-0c68-4942-b074-7f5c79fb6a20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#4. a.\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "from nltk import ne_chunk\n",
    "\n",
    "def extract_named_entities(ne_tree):\n",
    "    for entity in ne_tree:\n",
    "        if hasattr(entity, 'label'):\n",
    "            print(' '.join(c[0] for c in entity), '-', entity.label())\n",
    "\n",
    "# Perform NER\n",
    "ne_tree = ne_chunk(tagged_sent)\n",
    "# print(ne_tree)\n",
    "extract_named_entities(ne_tree)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f66d02c-4452-4db3-86a3-d4407d574c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk import CFG\n",
    "from nltk.parse import ChartParser, RecursiveDescentParser\n",
    "\n",
    "text = \"Men like Schiaparelli watched the red planet\"\n",
    "grammar_string = \"\"\"\n",
    "    S -> NP VP\n",
    "    VP -> V NP\n",
    "    NP -> N | Det N | N PP | Adj N\n",
    "    PP -> P NP\n",
    "    V -> \"watched\"\n",
    "    N -> \"Men\" | \"Schiaparelli\" | \"planet\"\n",
    "    Det -> \"the\"\n",
    "    P -> \"like\"\n",
    "    Adj -> \"red\"\n",
    "\"\"\"\n",
    "cfg = CFG.fromstring(grammar_string)\n",
    "parser = RecursiveDescentParser(cfg)\n",
    "\n",
    "# Split sentence\n",
    "split_text = text.split()\n",
    "for tree in parser.parse(split_text):\n",
    "    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e34d931-9a23-4f4e-9fa2-a479eb6d7db9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
